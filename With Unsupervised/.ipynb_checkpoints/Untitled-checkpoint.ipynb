{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import AutoEncoder\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        trained_model = AutoEncoder()\n",
    "        for param in trained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.encoder = nn.Sequential(*list(trained_model.children())[:-12])\n",
    "        \n",
    "#         self.unit1 = list(trained_model.children())[0]\n",
    "#         self.unit2 = list(trained_model.children())[1]\n",
    "#         self.pool1 = list(trained_model.children())[2]\n",
    "#         self.unit3 = list(trained_model.children())[3]\n",
    "#         self.unit4 = list(trained_model.children())[4]\n",
    "#         self.pool2 = list(trained_model.children())[5]\n",
    "#         self.unit5 = list(trained_model.children())[6]\n",
    "#         self.unit6 = list(trained_model.children())[7]\n",
    "#         self.pool3 = list(trained_model.children())[8]\n",
    "#         self.unit7 = list(trained_model.children())[9]\n",
    "#         self.unit8 = list(trained_model.children())[10]\n",
    "        \n",
    "        self.fc = nn.Linear(12*12*16, 1000)\n",
    "\n",
    "        exists = os.path.isfile('weights_sup.pth')\n",
    "        if exists:\n",
    "            print(\"Loading weights_sup\")\n",
    "            self.load_weights('weights_sup.pth')\n",
    "        else:\n",
    "            print(\"No weights_sup found. Starting Fresh\")\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "#         output = self.unit1(input)\n",
    "#         output = self.unit2(output)\n",
    "#         output, _= self.pool1(output)\n",
    "#         output = self.unit3(output)\n",
    "#         output = self.unit4(output)\n",
    "#         output, _ = self.pool2(output)\n",
    "#         output = self.unit5(output)\n",
    "#         output = self.unit6(output)\n",
    "#         output, _ = self.pool3(output)\n",
    "#         output = self.unit7(output)\n",
    "#         output = self.unit8(output)\n",
    "        output, _ = self.encoder(input)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def load_weights(self, pretrained_model_path, cuda=torch.cuda.is_available()):\n",
    "        # Load pretrained model\n",
    "        pretrained_model = torch.load(f=pretrained_model_path, map_location=\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "        # Load pre-trained s in current model\n",
    "        with torch.no_grad():\n",
    "            self.load_state_dict(pretrained_model, strict=torch.cuda.is_available())\n",
    "\n",
    "        # Debug loading\n",
    "        print('Parameters found in pretrained model:')\n",
    "        pretrained_layers = pretrained_model.keys()\n",
    "        for l in pretrained_layers:\n",
    "            print('\\t' + l)\n",
    "        print('')\n",
    "\n",
    "        for name, module in self.state_dict().items():\n",
    "            if name in pretrained_layers:\n",
    "                assert torch.equal(pretrained_model[name].cpu(), module.cpu())\n",
    "                print('{} have been loaded correctly in current model.'.format(name))\n",
    "            else:\n",
    "                raise ValueError(\"state_dict() keys do not match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights_unsup\n",
      "Parameters found in pretrained model:\n",
      "\tunit1.conv.weight\n",
      "\tunit1.conv.bias\n",
      "\tunit1.batch_norm.weight\n",
      "\tunit1.batch_norm.bias\n",
      "\tunit1.batch_norm.running_mean\n",
      "\tunit1.batch_norm.running_var\n",
      "\tunit1.batch_norm.num_batches_tracked\n",
      "\tunit2.conv.weight\n",
      "\tunit2.conv.bias\n",
      "\tunit2.batch_norm.weight\n",
      "\tunit2.batch_norm.bias\n",
      "\tunit2.batch_norm.running_mean\n",
      "\tunit2.batch_norm.running_var\n",
      "\tunit2.batch_norm.num_batches_tracked\n",
      "\tunit3.conv.weight\n",
      "\tunit3.conv.bias\n",
      "\tunit3.batch_norm.weight\n",
      "\tunit3.batch_norm.bias\n",
      "\tunit3.batch_norm.running_mean\n",
      "\tunit3.batch_norm.running_var\n",
      "\tunit3.batch_norm.num_batches_tracked\n",
      "\tunit4.conv.weight\n",
      "\tunit4.conv.bias\n",
      "\tunit4.batch_norm.weight\n",
      "\tunit4.batch_norm.bias\n",
      "\tunit4.batch_norm.running_mean\n",
      "\tunit4.batch_norm.running_var\n",
      "\tunit4.batch_norm.num_batches_tracked\n",
      "\tunit5.conv.weight\n",
      "\tunit5.conv.bias\n",
      "\tunit5.batch_norm.weight\n",
      "\tunit5.batch_norm.bias\n",
      "\tunit5.batch_norm.running_mean\n",
      "\tunit5.batch_norm.running_var\n",
      "\tunit5.batch_norm.num_batches_tracked\n",
      "\tunit6.conv.weight\n",
      "\tunit6.conv.bias\n",
      "\tunit6.batch_norm.weight\n",
      "\tunit6.batch_norm.bias\n",
      "\tunit6.batch_norm.running_mean\n",
      "\tunit6.batch_norm.running_var\n",
      "\tunit6.batch_norm.num_batches_tracked\n",
      "\tunit7.conv.weight\n",
      "\tunit7.conv.bias\n",
      "\tunit7.batch_norm.weight\n",
      "\tunit7.batch_norm.bias\n",
      "\tunit7.batch_norm.running_mean\n",
      "\tunit7.batch_norm.running_var\n",
      "\tunit7.batch_norm.num_batches_tracked\n",
      "\tunit8.conv.weight\n",
      "\tunit8.conv.bias\n",
      "\tunit8.batch_norm.weight\n",
      "\tunit8.batch_norm.bias\n",
      "\tunit8.batch_norm.running_mean\n",
      "\tunit8.batch_norm.running_var\n",
      "\tunit8.batch_norm.num_batches_tracked\n",
      "\ttinu1.conv.weight\n",
      "\ttinu1.conv.bias\n",
      "\ttinu1.batch_norm.weight\n",
      "\ttinu1.batch_norm.bias\n",
      "\ttinu1.batch_norm.running_mean\n",
      "\ttinu1.batch_norm.running_var\n",
      "\ttinu1.batch_norm.num_batches_tracked\n",
      "\ttinu2.conv.weight\n",
      "\ttinu2.conv.bias\n",
      "\ttinu2.batch_norm.weight\n",
      "\ttinu2.batch_norm.bias\n",
      "\ttinu2.batch_norm.running_mean\n",
      "\ttinu2.batch_norm.running_var\n",
      "\ttinu2.batch_norm.num_batches_tracked\n",
      "\ttinu3.conv.weight\n",
      "\ttinu3.conv.bias\n",
      "\ttinu3.batch_norm.weight\n",
      "\ttinu3.batch_norm.bias\n",
      "\ttinu3.batch_norm.running_mean\n",
      "\ttinu3.batch_norm.running_var\n",
      "\ttinu3.batch_norm.num_batches_tracked\n",
      "\ttinu4.conv.weight\n",
      "\ttinu4.conv.bias\n",
      "\ttinu4.batch_norm.weight\n",
      "\ttinu4.batch_norm.bias\n",
      "\ttinu4.batch_norm.running_mean\n",
      "\ttinu4.batch_norm.running_var\n",
      "\ttinu4.batch_norm.num_batches_tracked\n",
      "\ttinu5.conv.weight\n",
      "\ttinu5.conv.bias\n",
      "\ttinu5.batch_norm.weight\n",
      "\ttinu5.batch_norm.bias\n",
      "\ttinu5.batch_norm.running_mean\n",
      "\ttinu5.batch_norm.running_var\n",
      "\ttinu5.batch_norm.num_batches_tracked\n",
      "\ttinu6.conv.weight\n",
      "\ttinu6.conv.bias\n",
      "\ttinu6.batch_norm.weight\n",
      "\ttinu6.batch_norm.bias\n",
      "\ttinu6.batch_norm.running_mean\n",
      "\ttinu6.batch_norm.running_var\n",
      "\ttinu6.batch_norm.num_batches_tracked\n",
      "\ttinu7.conv.weight\n",
      "\ttinu7.conv.bias\n",
      "\ttinu7.batch_norm.weight\n",
      "\ttinu7.batch_norm.bias\n",
      "\ttinu7.batch_norm.running_mean\n",
      "\ttinu7.batch_norm.running_var\n",
      "\ttinu7.batch_norm.num_batches_tracked\n",
      "\ttinu8.conv.weight\n",
      "\ttinu8.conv.bias\n",
      "\ttinu8.batch_norm.weight\n",
      "\ttinu8.batch_norm.bias\n",
      "\ttinu8.batch_norm.running_mean\n",
      "\ttinu8.batch_norm.running_var\n",
      "\ttinu8.batch_norm.num_batches_tracked\n",
      "\n",
      "unit1.conv.weight have been loaded correctly in current model.\n",
      "unit1.conv.bias have been loaded correctly in current model.\n",
      "unit1.batch_norm.weight have been loaded correctly in current model.\n",
      "unit1.batch_norm.bias have been loaded correctly in current model.\n",
      "unit1.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit1.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit1.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit2.conv.weight have been loaded correctly in current model.\n",
      "unit2.conv.bias have been loaded correctly in current model.\n",
      "unit2.batch_norm.weight have been loaded correctly in current model.\n",
      "unit2.batch_norm.bias have been loaded correctly in current model.\n",
      "unit2.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit2.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit2.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit3.conv.weight have been loaded correctly in current model.\n",
      "unit3.conv.bias have been loaded correctly in current model.\n",
      "unit3.batch_norm.weight have been loaded correctly in current model.\n",
      "unit3.batch_norm.bias have been loaded correctly in current model.\n",
      "unit3.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit3.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit3.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit4.conv.weight have been loaded correctly in current model.\n",
      "unit4.conv.bias have been loaded correctly in current model.\n",
      "unit4.batch_norm.weight have been loaded correctly in current model.\n",
      "unit4.batch_norm.bias have been loaded correctly in current model.\n",
      "unit4.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit4.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit4.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit5.conv.weight have been loaded correctly in current model.\n",
      "unit5.conv.bias have been loaded correctly in current model.\n",
      "unit5.batch_norm.weight have been loaded correctly in current model.\n",
      "unit5.batch_norm.bias have been loaded correctly in current model.\n",
      "unit5.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit5.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit5.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit6.conv.weight have been loaded correctly in current model.\n",
      "unit6.conv.bias have been loaded correctly in current model.\n",
      "unit6.batch_norm.weight have been loaded correctly in current model.\n",
      "unit6.batch_norm.bias have been loaded correctly in current model.\n",
      "unit6.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit6.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit6.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit7.conv.weight have been loaded correctly in current model.\n",
      "unit7.conv.bias have been loaded correctly in current model.\n",
      "unit7.batch_norm.weight have been loaded correctly in current model.\n",
      "unit7.batch_norm.bias have been loaded correctly in current model.\n",
      "unit7.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit7.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit7.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "unit8.conv.weight have been loaded correctly in current model.\n",
      "unit8.conv.bias have been loaded correctly in current model.\n",
      "unit8.batch_norm.weight have been loaded correctly in current model.\n",
      "unit8.batch_norm.bias have been loaded correctly in current model.\n",
      "unit8.batch_norm.running_mean have been loaded correctly in current model.\n",
      "unit8.batch_norm.running_var have been loaded correctly in current model.\n",
      "unit8.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu1.conv.weight have been loaded correctly in current model.\n",
      "tinu1.conv.bias have been loaded correctly in current model.\n",
      "tinu1.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu1.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu1.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu1.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu1.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu2.conv.weight have been loaded correctly in current model.\n",
      "tinu2.conv.bias have been loaded correctly in current model.\n",
      "tinu2.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu2.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu2.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu2.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu2.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu3.conv.weight have been loaded correctly in current model.\n",
      "tinu3.conv.bias have been loaded correctly in current model.\n",
      "tinu3.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu3.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu3.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu3.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu3.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu4.conv.weight have been loaded correctly in current model.\n",
      "tinu4.conv.bias have been loaded correctly in current model.\n",
      "tinu4.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu4.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu4.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu4.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu4.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu5.conv.weight have been loaded correctly in current model.\n",
      "tinu5.conv.bias have been loaded correctly in current model.\n",
      "tinu5.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu5.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu5.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu5.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu5.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu6.conv.weight have been loaded correctly in current model.\n",
      "tinu6.conv.bias have been loaded correctly in current model.\n",
      "tinu6.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu6.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu6.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu6.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu6.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu7.conv.weight have been loaded correctly in current model.\n",
      "tinu7.conv.bias have been loaded correctly in current model.\n",
      "tinu7.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu7.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu7.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu7.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu7.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "tinu8.conv.weight have been loaded correctly in current model.\n",
      "tinu8.conv.bias have been loaded correctly in current model.\n",
      "tinu8.batch_norm.weight have been loaded correctly in current model.\n",
      "tinu8.batch_norm.bias have been loaded correctly in current model.\n",
      "tinu8.batch_norm.running_mean have been loaded correctly in current model.\n",
      "tinu8.batch_norm.running_var have been loaded correctly in current model.\n",
      "tinu8.batch_norm.num_batches_tracked have been loaded correctly in current model.\n",
      "No weights_sup found. Starting Fresh\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fbbe135b8738>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(summary(model, (3,96,96)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DL\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "model = Model().to(torch.device(\"cuda\"))\n",
    "# print(summary(model, (3,96,96)))\n",
    "model.encoder((3,96,96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
